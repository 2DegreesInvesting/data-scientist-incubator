[
["index.html", "ds-incubator Introduction", " ds-incubator Mauro Lepore CJ Yetman Jackson Hoffart Klaus Hagedorn Clare Murray 2019-10-22 Introduction This book contains materials presented at meetups of the ds-incubator. The goal of the ds-incubator (data science incubator) is to share best practices in coding. It helps us to become better data scientists and to improve out work at at 2° Investing Initiative and beyond. 0.0.1 Links: ds-incubator category on the blog Data science at 2DII. Meeting recordings. Meetup issues. Ideas for meetups. Depreated ds-incubator website / eBook. – This project is managed by Mauro with support from CJ and guidance from Klaus and Clare. Since mid-October, 2019 we meet online weekly. We welcome contributions from everyone at 2° Investing Initiative. ds-incubator by Mauro Lepore, CJ Yetman, Jackson Hoffart, Klaus Hagedorn, Clare Murray is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. "],
["setup-github-r-rstudio-git.html", "Chapter 1 2019-10-15: Setup GitHub, R, RStudio, Git 1.1 Register a free GitHub account 1.2 Install or update R and RStudio AND Install Git 1.3 Introduce yourself to Git (TODO) 1.4 Prove local Git can talk to GitHub (SKIP) 1.5 Cache your username and password or set up SSH keys (DONE) 1.6 Prove RStudio can find local Git (TODO) 1.7 Contemplate if you’d like to install an optional Git client", " Chapter 1 2019-10-15: Setup GitHub, R, RStudio, Git Based on Happy Git and GitHub for the useR, by Jenny Bryan, the STAT 545 TAs, and Jim Hester. 1.1 Register a free GitHub account Your username should be timeless, so you accumulate credit (exclude your employer; add your work email to your personal account). Your GitHub username, and definiterly your profile, should have your name. This makes it easy for people to search your name and find your username. People need your username to @mention you on GitHub (e.g. to thank you or discuss issues). 1.2 Install or update R and RStudio AND Install Git How to (a) think (b) about (c) upgrading software. If it hurts so it more often. If you have this kind of exponential relationship, then if you do it more frequently, you can drastically reduce the pain. – Martin Fowler in FrequencyReducesDifficulty 1.3 Introduce yourself to Git (TODO) # My ~/.gitconfig at the start git config --global --list #Email associated with GitHub git config --global user.email &quot;maurolepore@gmail.com&quot; git config --global user.name &quot;Mauro Lepore&quot; # Other very useful configurations git config --global push.default &quot;current&quot; git config --global core.editor &quot;notepad&quot; git config --global credential.helper &quot;manager&quot; # My ~/.gitconfig at the end git config --global --list 1.4 Prove local Git can talk to GitHub (SKIP) Login to http://github.com/ On GitHub: Create a repo Add description. Add README.md Copy https clone link On Git Bash: # Clone new repo and move to it git clone &lt;URL&gt; cd &lt;new repo&gt; # Edit README ## Before cat README.md echo &quot;A line from local computer&quot; &gt;&gt; README.md ## After cat README.md # Commit and push git add . git commit -m &quot;Edit README from local computer&quot; git push Check if credentials are managed correctly: Repeat edit, commit and push (you should no longer be challenged for a username and password). 1.5 Cache your username and password or set up SSH keys (DONE) We should be done. We already added this: git config —global credential.helper manager If we need to remove your git credentials on Windows, they are here: Control Panel &gt; user accounts &gt; credential manager &gt; Windows credentials &gt; Generic credentials SSH: Skip. 1.6 Prove RStudio can find local Git (TODO) Login to http://github.com/ On GitHub: Create a repo Add description. Add README.md Copy https clone link On RStudio: File &gt; New Project … &gt; Version Control &gt; Git Edit README, commit and push. Do it twice to confirm that the credential manager works as expected. 1.7 Contemplate if you’d like to install an optional Git client I recommend GitKraken: https://www.gitkraken.com/download "],
["encodings.html", "Chapter 2 2019-10-22: Encodings", " Chapter 2 2019-10-22: Encodings CJ Yetman https://github.com/2DegreesInvesting/ds-incubator/issues/7 "],
["pull-request-helpers.html", "Chapter 3 2019-10-29: pull request helpers 3.1 Setup 3.2 For contributors 3.3 More setup", " Chapter 3 2019-10-29: pull request helpers GitHub issue for this meetup. We’ll walk through the help file of the Helpers for GitHub pull requests 3.1 Setup Read Setup advice and if you need more help: Need more help? See More setup. 3.2 For contributors To contribute to a package, first use create_from_github(owner/repo) to fork the source repository, and then check out a local copy. Or fork and clone as usual. pr_init() 3.3 More setup Instructions to setup GitHub, R, RStudio, and Git. usethis setup Get and store a GitHub personal access token. "],
["usethispr-sync.html", "Chapter 4 2019-11-05: usethis::pr_sync( ) 4.1 create_from_github() 4.2 git_sitrep() 4.3 pr_init(\"pr\") 4.4 pr_push() 4.5 pr_sync() 4.6 Solve merge conflicts 4.7 pr_push() 4.8 [pr] now has no conflicts with [upstream/master] 4.9 pr_finish()", " Chapter 4 2019-11-05: usethis::pr_sync( ) Before merging your pull request, the source repository adds a conflicting commit. Now what? “pr_sync( ) is a shortcut for pr_pull( ), pr_pull_upstream( ), and pr_push( )” (usethis) https://twitter.com/mauro_lepore License: CCO 4.1 create_from_github() # Fork on GitHub, then run from a terminal: git clone git@github.com:maurolepore/abc.git cd abc # Contrib@LAPTOP ~/abc (master) git remote add upstream git@github.com:an-org/abc.git git pull upstream master git branch --set-upstream-to=upstream/master 4.2 git_sitrep() git remote -v 4.3 pr_init(\"pr\") # Contrib@LAPTOP ~/abc (master) git pull upstream master git branch pr git checkout pr 4.4 pr_push() # Contrib@LAPTOP ~/abc (pr) git push origin git branch --set-upstream-to=origin/pr https://github.com/maurolepore/abc/compare/pr But before [pr] is merged, the maintainer adds a conflicting change to the source repository 4.5 pr_sync() # Contrib@LAPTOP ~/abc (pr) # Using default remote &quot;origin&quot; and branch &quot;pr&quot; # `git pull` is shorthand for `git fetch &amp;&amp; git merge FETCH_HEAD` git pull git pull upstream master git push 4.6 Solve merge conflicts 4.7 pr_push() # Contrib@LAPTOP ~/abc (pr) # Retry sync git pull git pull upstream master git push 4.8 [pr] now has no conflicts with [upstream/master] 4.9 pr_finish() # Contrib@LAPTOP ~/abc (pr) git checkout master # Contrib@LAPTOP ~/abc (master) git pull upstream master git push -d origin pr git branch -d pr "],
["interdependent-pull-requests.html", "Chapter 5 2019-11-12: Interdependent pull requests 5.1 Situation 5.2 pr_init(\"pr1\") 5.3 New f() 5.4 pr_push() 5.5 pr_init(\"pr2\") 5.6 New g() 5.7 pr_push() 5.8 pr_fetch() (Maintainer) 5.9 Edit pr1 (Maintainer) 5.10 pr_push() (Maintainer) 5.11 pr_sync() 5.12 Fix pr2 then pr_push() 5.13 Squash-merge pr2 (Maintainer) 5.14 pr_finish()", " Chapter 5 2019-11-12: Interdependent pull requests 5.1 Situation After the contributor submitted a first pull request (pr1), and before the maintainer merges it into the source repository, the contributor starts a second pull request (pr2) that depends on pr1. The maintainer edits pr1 and accepts it (squash-merges it into the upstream/master). But pr2 now is a mess and the contributor must fix it before it can be merged. 5.2 pr_init(\"pr1\") 5.3 New f() 5.4 pr_push() 5.5 pr_init(\"pr2\") 5.6 New g() 5.7 pr_push() 5.8 pr_fetch() (Maintainer) 5.9 Edit pr1 (Maintainer) 5.10 pr_push() (Maintainer) 5.11 pr_sync() 5.12 Fix pr2 then pr_push() 5.13 Squash-merge pr2 (Maintainer) 5.14 pr_finish() "],
["installing-packages-in-r.html", "Chapter 6 2019-11-19: Installing packages in R", " Chapter 6 2019-11-19: Installing packages in R CJ Yetman Installing packages in R is more complicated than it seems Structure of a package R files Text based config files Help files Potentially source files in other languages (C, C++, Fortran, etc.) Submitted to CRAN, hosted on GitHub, or hosted on other CRAN-like repository (BioConductor, private repos, local etc.) Packages are primarily distributed as source packages (raw text files just as you would see in a GitHub repo for a package) BUT… some repos, like CRAN, pre-compile source packages into binaries which are platform specific EASY - when you install a binary package (if one is available for your platform), your R environment won’t have to do any processing to make the package work EASY - if only a source version of the package is available and the package is written entirely in R (plus various text config files and help files), your R environment should be able to process the package and prepare it for use on your machine without any trouble EASY-&gt;NIGHTMARE - if only a source version of the package is available and the package includes source files written in a language other than R, your machine will need to be fully setup as a development environment for whatever other languages are used macOS: command line developer tools plus custom clang and fortran https://cran.r-project.org/bin/macosx/tools/ Windows: Rtools https://cran.r-project.org/bin/windows/Rtools/ Suggestion: Install binary packages whenever possible remotes::install_github() (devtools::install_github()) devtools is a package of tools to help with package development remotes was created from just the install functions of devtools to create a light-weight package for installing from different locations There are numerous remotes::install_* functions These will install packages directly from their development repository Installs as source, with all the potential problems above Sometimes advantageous to get recent bug fixes etc. that have not been released on CRAN yet "],
["access-permissions-for-a-github-organization.html", "Chapter 7 2019-11-26: Access permissions for a GitHub organization 7.1 Situation 7.2 Set the usual plumbing 7.3 Initiate and work on your PR 7.4 Synchronize, push, and submit your PR 7.5 But something goes wrong 7.6 What happens when you push? 7.7 Owner, billing manager &amp; member 7.8 Members, teams &amp; outside collaborators 7.9 Permission levels for repositories 7.10 Permission levels for repositories (continued) 7.11 Example 7.12 Conclusion", " Chapter 7 2019-11-26: Access permissions for a GitHub organization https://github.com/2DegreesInvesting/ds-incubator/issues/14 https://twitter.com/mauro_lepore 7.1 Situation You want to propose changes to a source repo on a GitHub organization. Set the usual plumbing (create_from_github()). Initiate and work on your pull request (PR) (pr_init()). Synchronize, push, and submit your PR (pr_sync(), pr_push()). 7.2 Set the usual plumbing Fork source repo to your user account. Create a local clone of your fork. Connect your local clone with your fork (add remote origin). Connect your local clone with the source repo (add remote upstream). 7.3 Initiate and work on your PR Create a local branch to host PR. Change the local clone. Commit informing what changed and why. 7.4 Synchronize, push, and submit your PR Synchronize the source repository to get the latest changes. Push your PR to your fork. Submit your PR from your fork to the source repo. 7.5 But something goes wrong The set up involves too many steps. Unless you do it systematically (e.g. with usethis) sooner or later you will forget some step. For example, these are my most common mistakes: I copy the wrong URL so remote origin points to the source repo instead of my fork. I forget to create a new branch and add commits to my local master branch. 7.6 What happens when you push? Your commit(s) are now in the PR branch of your fork. Your commit(s) are now in the master branch of your fork. Your commit(s) are now in the PR branch of the source repo. Your commit(s) are now in the master branch of the source repo. You fail to push and get an error. It depends on your role and permission level: Roles: Owner, …, member, collaborator. Permission levels: Admin, …, push (write), read. 7.7 Owner, billing manager &amp; member Organization members can have owner, billing manager, or member roles. Owners have complete administrative access to your organization, while billing managers can manage billing settings. Member is the default role for everyone else. 7.8 Members, teams &amp; outside collaborators You can set the default of what members can do for all repos. You can manage access permissions for multiple members at a time with teams. You can invite outside collaborators to give them access to specific repositories. 7.9 Permission levels for repositories Read: Recommended for non-code contributors who want to view or discuss your project. Triage: Recommended for contributors who need to proactively manage issues and PRs without write access. Write: Recommended for contributors who actively push to your project. Maintain: Recommended for project managers who need to manage the repository without access to sensitive or destructive actions. … 7.10 Permission levels for repositories (continued) … Admin: Recommended for people who need full access to the project, including sensitive and destructive actions like managing security or deleting a repository. Organization owners have admin permissions for every repository owned by the organization (table). 7.11 Example 7.11.1 Org settings: People 7.11.2 An owner’s privileges 7.11.3 Org settings: Member privileges 7.11.4 Repo settings: Collaborators &amp; teams 7.11.5 Repo settings: Branches 7.12 Conclusion “You do not rise to the level of your goals. You fall to the level of your systems” – James Clear, Atomic Habits People should have just the access they need. Be pragmatic. "],
["avoid-hidden-arguments.html", "Chapter 8 2019-12-03: Avoid hidden arguments 8.1 Hidden arguments make code harder to reason about, because to correctly predict the output you also need to know some other state 8.2 Functions are easier to understand if the results depend only on the values of the inputs 8.3 How can I remediate the problem? 8.4 For example, take prepare_data() 8.5 1. prepare_data() gains the explicit argument data 8.6 2. prepare_data() now prints data 8.7 But data should be supplied 8.8 A function has hidden arguments when it returns different results with the same inputs in a surprising way 8.9 Surprising 8.10 Not surprising", " Chapter 8 2019-12-03: Avoid hidden arguments – Tidyverse design guide https://twitter.com/mauro_lepore License: CCO 8.1 Hidden arguments make code harder to reason about, because to correctly predict the output you also need to know some other state y &lt;- 1 add &lt;- function(x) { x + y } add(1) #&gt; [1] 2 y &lt;- 10 ## It is hard to keep track of this add(1) #&gt; [1] 11 8.2 Functions are easier to understand if the results depend only on the values of the inputs 8.3 How can I remediate the problem? If you have an existing function with a hidden input: Make sure the input is an explicit option. Make sure it’s printed. 8.4 For example, take prepare_data() The output depends on data, but it is hidden. prepare_data &lt;- function() { data &lt;- read.csv(path) data[1:2, 1:2] } path &lt;- tempfile() readr::write_csv(mtcars, path) prepare_data() #&gt; mpg cyl #&gt; 1 21 6 #&gt; 2 21 6 8.5 1. prepare_data() gains the explicit argument data prepare_data &lt;- function(data = read.csv(path)) { data[1:2, 1:2] } prepare_data() #&gt; mpg cyl #&gt; 1 21 6 #&gt; 2 21 6 8.6 2. prepare_data() now prints data prepare_data &lt;- function(data = read.csv(path)) { if (missing(data)) { message( &quot;Using `data` with names: &quot;, paste(names(data), collapse = &quot;, &quot;) ) } data[1:2, 1:2] } prepare_data() #&gt; Using `data` with names: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb #&gt; mpg cyl #&gt; 1 21 6 #&gt; 2 21 6 prepare_data(read.csv(path)) #&gt; mpg cyl #&gt; 1 21 6 #&gt; 2 21 6 8.7 But data should be supplied Data arguments provide the core data. They are required, and are usually vectors and often determine the type and size of the output. Data arguments are often called data, x, or y – tidyverse design guide. prepare_data &lt;- function(data) { data[1:2, 1:2] } try(prepare_data()) #&gt; Error in prepare_data() : argument &quot;data&quot; is missing, with no default data &lt;- read.csv(path) prepare_data(data) #&gt; mpg cyl #&gt; 1 21 6 #&gt; 2 21 6 Some functions do need to depend on external state … 8.8 A function has hidden arguments when it returns different results with the same inputs in a surprising way 8.9 Surprising getOption(&quot;stringsAsFactors&quot;) #&gt; [1] FALSE data.frame(x = &quot;a&quot;)$x #&gt; [1] &quot;a&quot; old_options &lt;- options(stringsAsFactors = FALSE) on.exit(old_options) getOption(&quot;stringsAsFactors&quot;) #&gt; [1] FALSE data.frame(x = &quot;a&quot;)$x #&gt; [1] &quot;a&quot; Global options should not affect computation. 8.10 Not surprising read_csv(path) depends not only on path but also on the contents of the file, but that is not surprising. library(readr) path &lt;- tempfile() write_csv(mtcars, path) names(read_csv(path)) #&gt; [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; #&gt; [11] &quot;carb&quot; write_csv(iris, path) names(read_csv(path)) #&gt; [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; &quot;Species&quot; "],
["reprex.html", "Chapter 9 2019-12-10 reprex 9.1 The working directory", " Chapter 9 2019-12-10 reprex reprex usage Reprex do’s and don’ts This seems like a lot of work! Using datapasta with reprex 9.1 The working directory By default, reprex works on a temporary directory. reprex::reprex(getwd()) yields getwd() #&gt; [1] &quot;C:/Users/Mauro/AppData/Local/Temp/RtmpcDRddU/reprex108c190d657&quot; Use outfile = NA to work on your project’s working directory. reprex::reprex(getwd(), outfile = NA) yields getwd() #&gt; [1] &quot;C:/Users/Mauro/git/ds-incubator&quot; (See the full description of outfile at ?reprex::reprex().) And reprex::reprex(readr::read_csv(&quot;your-file.csv&quot;), outfile = NA) yields readr::read_csv(&quot;your-file.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; Time = col_double(), #&gt; demand = col_double() #&gt; ) #&gt; # A tibble: 6 x 2 #&gt; Time demand #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 8.3 #&gt; 2 2 10.3 #&gt; 3 3 19 #&gt; 4 4 16 #&gt; 5 5 15.6 #&gt; 6 7 19.8 "],
["reusing-tidyverse-code.html", "Chapter 10 2019-12-17: Reusing tidyverse code 10.1 Resources", " Chapter 10 2019-12-17: Reusing tidyverse code 10.1 Resources Tidy eval in context, rstudio::conf 2019, Jenny Bryan. Reusing tidyverse code, UseR 2019, Lionel Henry. Advanced R, ed. 2, ch. 17-21, Hadley Wickham. rlang package, Lionel Henry, Hadley Wickham. "],
["retrospective.html", "Chapter 11 2020-01-07: Retrospective", " Chapter 11 2020-01-07: Retrospective CJ Yetman and Mauro Lepore https://github.com/2DegreesInvesting/ds-incubator/issues/18 "],
["project-oriented-workflow.html", "Chapter 12 2020-01-14: Project-oriented workflow 12.1 Workflow versus product 12.2 Self-contained projects 12.3 setwd( ) 12.4 rm(list = ls( ))", " Chapter 12 2020-01-14: Project-oriented workflow Project-oriented workflow –Jenny Bryan 12.1 Workflow versus product 12.1.1 Definitions Workflow: personal taste and habits. Product: essence of your project. Don’t hardwire your workflow into your product. 12.1.2 Which is workflow or product? The editor you use to write your R code. The raw data. The name of your home directory. The R code someone needs to run on your raw data to get your results, including the explicit library() calls to load necessary packages. 12.1.3 Example: Remove workflow The name of the home directory is workflow, not product. home &lt;- &quot;C:/Users/Mauro/Documents/&quot; # Workflow proj_path &lt;- &quot;path/to/project&quot; paste0(home, proj_path) #&gt; [1] &quot;C:/Users/Mauro/Documents/path/to/project&quot; Better proj_path &lt;- &quot;path/to/project&quot; fs::path_home_r(proj_path) #&gt; /home/mauro/path/to/project Best fs::path_home_r(&quot;path&quot;, &quot;to&quot;, &quot;project&quot;) #&gt; /home/mauro/path/to/project 12.2 Self-contained projects 12.2.1 Self-contained projects can be moved around on your computer or onto other computers and will still “just work”. It’s like agreeing that we will all drive on the left or the right. A hallmark of civilization is following conventions that constrain your behavior a little, in the name of public safety. –Jenny Bryan 12.2.2 What do they look like? The Project folder contains all relevant files. Any .R can run from a fresh R process with wd set to root. Any .R creates all it needs, in its own workspace or folder Any .R touches nothing it didn’t create (e.g. doesn’t install). 12.2.3 Violations … 12.2.4 What should you do instead of this? path_to_data &lt;- &quot;../datasets/my-data.csv&quot; 12.2.5 What should you do instead? 12.2.6 What should you do instead of this? pacman::p_load(random) 12.3 setwd( ) 12.3.1 What’s wrong? library(ggplot2) setwd(&quot;/Users/jenny/cuddly_broccoli/verbose_funicular/foofy/data&quot;) df &lt;- read.delim(&quot;raw_foofy_data.csv&quot;) p &lt;- ggplot(df, aes(x, y)) + geom_point() ggsave(&quot;../figs/foofy_scatterplot.png&quot;) 12.3.2 What’s wrong? Paths work for nobody besides the author. Project not self-contained and portable. To run, it first needs to be hand edited. Suggests that the useR does all of their work in one R process: Unpleasant to work on more than one project at a time Easy for work done on one project to accidentally leak into another (e.g., objects, loaded packages, session options). 12.3.3 What should you do instead? Use RStudio projects, and/or Use the here package (works well with .Rmd files) library(ggplot2) library(here) df &lt;- read.delim(here(&quot;data&quot;, &quot;raw_foofy_data.csv&quot;)) p &lt;- ggplot(df, aes(x, y)) + geom_point() ggsave(here(&quot;figs&quot;, &quot;foofy_scatterplot.png&quot;)) 12.4 rm(list = ls( )) 12.4.1 What’s wrong? Suggests the useR works in one long-running (not fresh) R process. Does NOT, in fact, create a fresh R process – it only deletes objects from the global workspace but leaves stuff that make your script vulnerable to hidden dependencies (e.g. packages, options, working directory). Is hostile to anyone that you ask to help you with your R problems. 12.4.2 What’s better? Start from blank slate. Restart R very often. Re-run your under-development script from the top. For long running processes: Isolate slow bit in its own script; write it with saveRDS() and read it with readRDS(), or Use drake. 12.4.3 Discuss: Must have or nice to have? The importance of these practices has a lot to do with whether your code will be run by other people, on other machines, and in the future. If your current practices serve your purposes, then go forth and be happy – Jenny Bryan 12.4.4 Learn more What They Forgot to Teach You About R (Jenny Bryan &amp; Jim Hester). "],
["debugging-with-rstudio.html", "Chapter 13 2020-01-21: Debugging with rstudio", " Chapter 13 2020-01-21: Debugging with rstudio Jackson Hoffart https://github.com/2DegreesInvesting/ds-incubator/issues/21 "],
["our-resources.html", "Chapter 14 2020-01-28: Our resources 14.1 ds-incubator eBook: bit.ly/2dii-ds-incubator 14.2 ds-incubator on rstudio.cloud: bit.ly/rs-cloud-ds-incubator 14.3 # coding 14.4 Miscellaneous resources 14.5 Poroposed topics for meetups (#11) 14.6 Gotchas 14.7 r2dii", " Chapter 14 2020-01-28: Our resources 14.1 ds-incubator eBook: bit.ly/2dii-ds-incubator 14.2 ds-incubator on rstudio.cloud: bit.ly/rs-cloud-ds-incubator 14.3 # coding 14.4 Miscellaneous resources 14.5 Poroposed topics for meetups (#11) 14.6 Gotchas 14.7 r2dii "],
["r-packages-setup.html", "Chapter 15 2020-02-04: R packages: Setup 15.1 https://r-pkgs.org/whole-game.html 15.2 The demo package 15.3 Packaging gotchas", " Chapter 15 2020-02-04: R packages: Setup 15.1 https://r-pkgs.org/whole-game.html 15.2 The demo package On RStudio desktop, I created the demo package and pushed it to GitHub. create_package(&quot;demo&quot;) use_git() use_github(&quot;2degreesinvesting&quot;) On GitHub, I forked the demo package from 2degreesinvesting/demo to maurolepore/demo. On the ds-incubator workspace on rstudio.cloud, I created a new repo from GitHub and added packages from the base project (devtools and friends). You may copy the demo project from rstudio.cloud: https://rstudio.cloud/spaces/47358/project/908370 15.3 Packaging gotchas "],
["r-packages-data.html", "Chapter 16 2020-02-11: R packages: Data 16.1 Exported data: data/ 16.2 Document exported data 16.3 Internal data: R/sysdata.rda 16.4 Raw data for users: inst/extdata 16.5 dput(), tibble::tribble(), datapasta::tribble_paste()", " Chapter 16 2020-02-11: R packages: Data From https://r-pkgs.org/data.html 16.1 Exported data: data/ If you want to store binary data and make it available to the user, put it in data/. This is the best place to put example datasets. use_data_raw() # data-raw/mini_mtcars.R # Prepare mini_mtcars &lt;- head(mtcars) usethis::use_data(mini_mtcars) 16.2 Document exported data # R/mini_mtcars.R #&#39; First six rows of [datasets::mtcars] #&#39; #&#39; A mini dataset for examples and tests. #&#39; #&#39; @source [datasets::mtcars] &quot;mini_mtcars&quot; 16.3 Internal data: R/sysdata.rda If you want to store parsed data, but not make it available to the user, put it in R/sysdata.rda. This is the best place to put data that your functions need. # data-raw/sysdata.R mini_letters &lt;- head(letters) mini_month &lt;- head(month.abb) usethis::use_data(mini_letters, mini_month, internal = TRUE) 16.4 Raw data for users: inst/extdata If you want to store raw data, put it in inst/extdata. use_directory(&quot;inst/extdata&quot;) system.file(&quot;extdata&quot;, &quot;iris.csv&quot;, package = &quot;readr&quot;, mustWork = TRUE) 16.5 dput(), tibble::tribble(), datapasta::tribble_paste() A simple alternative to these three options is to include it in the source of your package, either creating by hand, or using dput() to serialise an existing data set into R code. datasets::BOD #&gt; Time demand #&gt; 1 1 8.3 #&gt; 2 2 10.3 #&gt; 3 3 19.0 #&gt; 4 4 16.0 #&gt; 5 5 15.6 #&gt; 6 7 19.8 dput(datasets::BOD) #&gt; structure(list(Time = c(1, 2, 3, 4, 5, 7), demand = c(8.3, 10.3, #&gt; 19, 16, 15.6, 19.8)), class = &quot;data.frame&quot;, row.names = c(NA, #&gt; -6L), reference = &quot;A1.4, p. 270&quot;) "],
["testing.html", "Chapter 17 2020-02-18: Testing 17.1 Why? 17.2 How? 17.3 What 17.4 What", " Chapter 17 2020-02-18: Testing From https://r-pkgs.org/tests.html 17.1 Why? 17.2 How? usethis::use_testthat() R/a_function.R tests/testthat/test-a_function.R test_that(&quot;a_function ....&quot;, { expect_that(a_) }) Hierarchical structure 17.3 What Whenever you are tempted to type something into a print statement or a debugger expression, write it as a test instead. — Martin Fowler 17.4 What Test what should work Test what should fail and how "],
["r-packages-documenting.html", "Chapter 18 2020-02-18: R packages: Documenting 18.1 Objectives 18.2 Why is documenting important? 18.3 Code &gt; Insert Roxygen Skeleton 18.4 How useful are examples? 18.5 README: usethis::use_readme_rmd() 18.6 Websites", " Chapter 18 2020-02-18: R packages: Documenting https://github.com/2DegreesInvesting/ds-incubator/issues/26 18.1 Objectives Why documenting your package is important for users and developers. How to generate a roxygen skeleton to document a function. Why the examples section is important? Why README is important? What are common README gotchas Why README can’t find functions in your package? Why README should not use tidyverse How to navigate a package website. 18.2 Why is documenting important? How it helps users? How it helps developers? Why using a consistent format might be useful for users/developers? 18.3 Code &gt; Insert Roxygen Skeleton #&#39; Title #&#39; #&#39; @param x #&#39; #&#39; @return #&#39; @export #&#39; #&#39; @examples f &lt;- function(x) { x } – NOTE: @cjyetman recommended to always document explicitly the expected type of each argument to a function. @2diiKlaus endorsed the comment and asks to do it in all packages we build. @maurolepore would like to develop a template. Follow this discussion. 18.4 How useful are examples? Help users understand how to use a function. Help developers understand what a function should do. Can be reused in tests/ and README 18.5 README: usethis::use_readme_rmd() Gotchas: Used packages (library()) need to be listed in DESCRIPTION. Your package needs to be installed (devtools::install()). Needs to be in sync with README.md (i.e. must knit). tip: tidyverse is for EDA not packages (This rigor feels annoying but helps find problems with the package structure.) 18.6 Websites usethis::use_pkgdown() + pkgdown::build_site(). GitHub &gt; Settings &gt; GitHub Pages: Choose “master branch docs/ folder” "],
["watch-out-for-type-inconsistent-code.html", "Chapter 19 2020-03-03: Watch out for type-inconsistent code", " Chapter 19 2020-03-03: Watch out for type-inconsistent code CJ https://github.com/2DegreesInvesting/ds-incubator/issues/28 "],
["pair-programming.html", "Chapter 20 2020-03-10: Pair programming 20.1 Driver - navigator 20.2 Overview 20.3 Ping pong style 20.4 Strong-Style Pairing 20.5 Discuss: Benefits (5’) 20.6 Discuss: Challenges (5’) 20.7 To pair or not to pair 20.8 Problems with code review vs. pairing 20.9 Why bother?", " Chapter 20 2020-03-10: Pair programming 20.1 Driver - navigator 20.2 Overview benefits are not immediately obvious not as simple as “two people working at a single computer” feels uncomfortable vital for collaborative teamwork and high quality software – https://martinfowler.com/articles/on-pair-programming.html 20.3 Ping pong style 20.4 Strong-Style Pairing The rule: For an idea to go from your head into the computer it MUST go through someone else’s hands. Particularly useful for knowledge transfer 20.5 Discuss: Benefits (5’) 20.6 Discuss: Challenges (5’) Pairing can be exhausting Intense collaboration can be hard Interruptions by meetings Different skill levels Power Dynamics Pairing with lots of Unknowns No time for yourself Rotations lead to context switching Pairing requires vulnerability Convincing managers and co-workers 20.7 To pair or not to pair Boring Tasks Need space to figure things out 20.8 Problems with code review vs. pairing not looking too closely at the code. avoid rework for something that we invested in. disruptive to switch context 20.9 Why bother? It takes: Concentration and focus (suitable style), task organization (find problem, solution, and plan), time management (e.g. pomodoro), communication, giving and receiving feedback, empathy, vulnerability Work on getting better at it, you will end up with a more resilient team. "],
["coding-sprint-retrospective.html", "Chapter 21 2020-03-17 Coding-sprint retrospective 21.1 What when well? 21.2 What didn’t go so well? 21.3 How can we do better next time?", " Chapter 21 2020-03-17 Coding-sprint retrospective https://github.com/2DegreesInvesting/ds-incubator/issues/30 21.1 What when well? People liked working with someone else on the same problem at the same time. We feel that was fun and allowed us to share knowledge (e.g. Jackson showed how to build 2dii-like packages). 21.2 What didn’t go so well? The organization of the sprint could have been better. The communication before and during the sprint was little, both among organizers and between organizers and participants. The vision of the organizers and participants were misaligned. Interdependent tasks were not scheduled to maximize efficiency. For example, the r2dii.scenario package wasn’t ready on GitHub to push commits to it, and one PR had to wait. It was unclear who was the “go-to person” for specific technical or conceptual knowledge. It was unclear that the event was happening until too close to the starting date. It was unclear what tasks we could work on. Except for the kick-off meeting, there was no scheduled time to catch up or wrap up. Prior commitments might have interrupted team work. Work was sometimes unfocused and people “got lost in the woods”. 21.3 How can we do better next time? (1-3 above) Have preparatory meeting among the organizers, and between organizers and participants before and during the event. Before the event to: Align vision Specify responsibilities Set clear agenda Prepare introduction providing more context and content than in the current one to ensure everyone understand the goal of a) the entire workshop as well as b) of each specific task/function During the event to: Ensure everyone is working with someone else and feeling okay. Check if the work in progress is going well and and as planned. Maybe answer: (a) What did we do so far? (b) What do we plan to do? (c) What is impairing our progress? (4 above) Once all tasks are clear and before people get to work, search for interdependent tasks and schedule them for maximum efficiency. It may help to write each task on a GitHub issue (or sticky note), organize them on a GitHub project board (or the wall), then schedule them with GitHub milestones (or an alarm clock). (5 above) Nominate technical and conceptual mentors, who could and are willing to train others or navigate pair-programming sessions with those seeking the knowledge they have. (5 above) Ensure mentors are well advertised, are enough, available, and easy to reach. Each mentor should probably have a personal zoom account, be trained in pair-programming, and know how to remote-control a shared screen. (6 above) Once we set a date for the sprint, advertise it ASAP and clarify if the cancellation of an in-person event means (a) the event is indeed canceled, or (b) the event happens remotely. (7 above) Dedicate a repository to the event and collect ideas and comments in the form of GitHub issues (example from others). Each issue may be a piece of the work that needs to be done to address a bigger problem. The dedicated, smaller issues should allow people to discuss and extend your ideas. We should encourage people to self nominate to tackle one of those issues or to propose a new issue. (8 above) Meet everyone at scheduled times during the sprint to check progress, and also at the end of the event to wrap up. (9 above) Ask break-out groups (maybe pairs) to talk to each other and schedule blocks of uninterrupted time to work together. (10 above) Start with a time slot for break-out groups to plan their work (scoping, approach, etc.). Also: Encourage working in groups (at least two people most of the time). Pair-programming is a great way to share knowledge, particularly the strong-style pairing but it seems best to mix with other pairing styles. Pairing requires vulnerability and everyone should feel safe and comfortable working with others, regardless of their technical skills. Lean how others do similar things, e.g.: https://mozilla.github.io/global-sprint/ https://ropensci.org/blog/2017/11/17/unconf-sixtips/ https://chircollab.github.io/#about "],
["refactoring-prepare-for-dplyr-1-0-0.html", "Chapter 22 2020-03-24: Refactoring: Prepare for dplyr 1.0.0 22.1 Content 22.2 Resources", " Chapter 22 2020-03-24: Refactoring: Prepare for dplyr 1.0.0 This meetup is for you if you use dplyr or want an overview of refactoring. dplyr 1.0.0 is comming soon. I includes great new features but also many changes that can break your code. You will likely need to change your code, and you can save time and pain of you know about Refactoring. 22.1 Content Where to find dplyr’s breaking changes and new features How to isolate your projects with renv. DEMO If the potential for changes makes you nervous, now is a good time to learn about renv. renv allows to create isolated, reproducible, projects so that you can experiment with new package versions while feeling secure that your existing projects will continue to work as they always have. – https://www.tidyverse.org/blog/2020/03/dplyr-1-0-0-is-coming-soon/ Refactoring What is it? “Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior”. Rename variable Catalog DEMO Why is it useful to have tests. Why is it useful to use Git. 22.2 Resources Video recording Refactoring: What is it? and catalog. Tidyverse blog dplyr 1.0.0 is comming soon summarize() rowwise() colwise() Breaking changes and other dplyr NEWS.md renv Help desk hours with CJ, Jackson, and Mauro (details to come) "],
["r2dii-data-and-r2dii-match-are-now-on-cran.html", "Chapter 23 2020-03-31: r2dii.data and r2dii.match are now on CRAN 23.1 How to find out what we have? 23.2 How to install and use? 23.3 Discuss: What does it take to publish a package on CRAN? 23.4 Resources", " Chapter 23 2020-03-31: r2dii.data and r2dii.match are now on CRAN This meetup is to bring attention the the newly-CRAN published packages r2dii.data and r2dii.match, the first two packages published as part of the r2dii suite. 23.1 How to find out what we have? Where to keep an eye on all r2dii packages updates: r2dii In particular, new package releases and patch notes + author acknowledgements will be found on the NEWS tab Currently published packages on CRAN: r2dii.data and r2dii.match Package websites: r2dii.data and r2dii.match 23.2 How to install and use? Packages can now be installed as usual in R: install.packages(&quot;r2dii.data&quot;) install.packages(&quot;r2dii.match&quot;) Brief DEMO 23.3 Discuss: What does it take to publish a package on CRAN? 23.4 Resources Demo materials: 2020-03-31_r2dii-cran-demo/r2dii.data_demo.R 2020-03-31_r2dii-cran-demo/r2dii.match_demo.R See also: Recording https://2degreesinvesting.github.io/r2dii.data/ https://2degreesinvesting.github.io/r2dii.match/ "],
["tidying-data.html", "Chapter 24 2020-04-08: Tidying data", " Chapter 24 2020-04-08: Tidying data Comparing gather to pivot_longer and spread to pivot_wider (GitHub issue) @cjyetman run a live example, answered questions, and lead the discussion (recording; code). You may like this content if you use tidyverse packages to analyze tidy data (as defined here and here). This includes 2DII folks and beyond. Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores. – https://vita.had.co.nz/papers/tidy-data.pdf "],
["manage-data-with-pins.html", "Chapter 25 2020-04-21: Manage data with pins 25.1 Who is the audience? 25.2 Why is this important? 25.3 What should be covered? 25.4 Suggested speakers or contributors 25.5 Resources 25.6 Q&amp;A and discussion", " Chapter 25 2020-04-21: Manage data with pins https://github.com/2DegreesInvesting/ds-incubator/issues/38 25.1 Who is the audience? Analysts, data managers, software developers at 2DII and beyond. 25.2 Why is this important? Following a discussion on managing and using data (#35) we concluded we can improve. Before we invest in any one approach we may want to explore a number of potentially good alternatives. A system would be a good candidate if it has this properties: Allows us to control permissions to read and write data Supports version control with Git and GitHub – tools we already know. Hosts data online yet allows using a data from a cache stored locally. Can handle datasets of the maximum size we need. Plays well with R, and maybe Python. Is low cost or better free. Implements tools that are as familiar as possible, e.g. git and GitHub as opposed 25.3 What should be covered? Show how the pins package meets these requirements. Discuss what requirements I forgot to list. Questions and answers. 25.4 Suggested speakers or contributors I plan to run a demo, then expect questions, and comments from everyone else. 25.5 Resources pins package Recording - just demo (10’) Recording - demo + discussion (30’) 25.6 Q&amp;A and discussion Questions: Where does the cache live? Does it work with private repos? What happens if I don’t have internet? How about memoise::memoise()? What is the maximum size of files we have? (thanks (???)) Azure has no upper limit on file size (thanks (???)) File format plays an important role (thanks (???)) Suggestions: Table different alternatives to better see pros and cons (thanks (???)) "],
["the-flow-of-data.html", "Chapter 26 2020-04-27: The flow of data 26.1 The data science workflow 26.2 The input/output of data is implicit 26.3 Data represented explicitly 26.4 Best is to allow local and remote access 26.5 Dropbox 26.6 pins 26.7 Today: Get data from the database", " Chapter 26 2020-04-27: The flow of data https://github.com/2DegreesInvesting/ds-incubator/issues/40 26.1 The data science workflow R for data science 26.2 The input/output of data is implicit 26.3 Data represented explicitly 26.4 Best is to allow local and remote access 26.5 Dropbox rdrop2: Programmatic Interface to the ‘Dropbox’ API 26.6 pins pins: Pin, Discover and Share Resources 26.7 Today: Get data from the database "],
["get-data-directly-from-the-database.html", "Chapter 27 2020-04-27: Get data directly from the database 27.1 File “test_db_portcheck.R” 27.2 File “simulate_portcheck_code.R”", " Chapter 27 2020-04-27: Get data directly from the database The relevant issue is this, and the code that CJ showed today is below. 27.1 File “test_db_portcheck.R” library(dplyr) library(dbplyr) library(readr) library(fs) library(tictoc) # Connection functions connect_datastore &lt;- function(data_quarter = &#39;_2019q4&#39;) { require(DBI) require(RPostgres) if (is.null(getOption(&#39;2dii_datastore_pwd&#39;))) { set_datastore_pwd() } DBI::dbConnect( drv = RPostgres::Postgres(), dbname = &#39;twodii&#39;, host = &#39;twodii-gocd.westeurope.cloudapp.azure.com&#39;, user = &#39;twodii-reader&#39;, password = getOption(&#39;2dii_datastore_pwd&#39;), options = paste0(&#39;-c search_path=&#39;, data_quarter, &#39;,public&#39;) ) } set_datastore_pwd &lt;- function() { require(rstudioapi) options(&#39;2dii_datastore_pwd&#39; = rstudioapi::askForPassword(&#39;Database password&#39;)) } # Access dropbox_path &lt;- fs::path(&#39;~/Dropbox (2° Investing)&#39;) project_path_rds &lt;- fs::path(&#39;PortCheck/00_Data/07_AnalysisInputs/2019Q4_250220&#39;) fin_data_rds &lt;- read_rds(fs::path(dropbox_path, project_path_rds, &#39;security_financial_data.rda&#39;)) fin_data_rds dropbox_path &lt;- fs::path(&#39;~/Dropbox (2° Investing)&#39;) project_path_csv &lt;- fs::path(&#39;PortCheck/00_Data/06_DataStore/2019Q4_export_04232020/2019Q4&#39;) fin_data_csv &lt;- read_csv(fs::path(dropbox_path, project_path_csv, &#39;security_financial_data.csv&#39;)) fin_data_csv datastore &lt;- connect_datastore(data_quarter = &#39;_2019q4&#39;) fin_data_db &lt;- tbl(datastore, &#39;security_financial_data&#39;) fin_data_db # Advantages: # 1. Doesn&#39;t depend on the name of the Dropbox folder # 2. Don&#39;t have to figure out the proper filepath # 3. Don&#39;t have to worry about cross-platform filepath formatting # 4. Don&#39;t have to be connected to Dropbox at all # 5. Don&#39;t have to worry about column types (read_csv) # 6. Explicit paths make packaging the code for other uses very difficult # Disadvantage: # 1. Does require internet access (potentially worked around by implementing # a caching system) # Speed tic() fin_data_rds &lt;- read_rds(fs::path(dropbox_path, project_path_rds, &#39;security_financial_data.rda&#39;)) fin_data_rds toc() tic() fin_data_csv &lt;- read_csv(fs::path(dropbox_path, project_path_csv, &#39;security_financial_data.csv&#39;)) fin_data_csv toc() tic() fin_data_db &lt;- tbl(datastore, &#39;security_financial_data&#39;) fin_data_db toc() tic() fin_data_db &lt;- tbl(datastore, &#39;security_financial_data&#39;) fin_data_db %&gt;% collect() toc() tic() fin_data_db &lt;- tbl(datastore, &#39;security_financial_data&#39;) fin_data_db %&gt;% select(company_id, bloomberg_id, company_name, isin, security_bics_subgroup) %&gt;% collect() toc() # Disadvantage: # 1. Has to download the data over the internet, but... if you specify only # the parts of the data you need, it can still be pretty fast, even faster # than reading in the whole local file under certain circumstances # PACTA analysis # get_and_clean_fin_data() source(&#39;simulate_portcheck_code.R&#39;) tic() fin_data_rds &lt;- read_rds(fs::path(dropbox_path, project_path_rds, &#39;security_financial_data.rda&#39;)) clean_fin_data(fin_data_rds) toc() tic() fin_data_csv &lt;- read_csv(fs::path(dropbox_path, project_path_csv, &#39;security_financial_data.csv&#39;)) clean_fin_data(fin_data_csv) toc() tic() fin_data_db &lt;- tbl(datastore, &#39;security_financial_data&#39;) clean_fin_data(fin_data_db) toc() tic() fin_data_db &lt;- tbl(datastore, &#39;security_financial_data&#39;) clean_fin_data(fin_data_db) %&gt;% collect() toc() # Advanced usage fin_data_db &lt;- tbl(datastore, &#39;security_financial_data&#39;) bics_sub_lookup &lt;- fin_data_db %&gt;% select(isin, security_bics_subgroup) company_name_lookup &lt;- fin_data_db %&gt;% select(isin, company_name) coupon_value_lookup &lt;- fin_data_db %&gt;% select(isin, coupon_value) bics_sub_lookup company_name_lookup coupon_value_lookup bics_sub_lookup %&gt;% collect() company_name_lookup %&gt;% collect() coupon_value_lookup %&gt;% collect() isins &lt;- fin_data_db %&gt;% select(isin) %&gt;% collect() %&gt;% filter(!is.na(isin)) isins &lt;- isins[sample(1:nrow(isins), 20), ] isins isins %&gt;% left_join(bics_sub_lookup, copy = TRUE) %&gt;% print(n = 20) isins %&gt;% left_join(company_name_lookup, copy = TRUE) %&gt;% print(n = 20) isins %&gt;% left_join(coupon_value_lookup, copy = TRUE) %&gt;% print(n = 20) isins %&gt;% left_join(fin_data_db %&gt;% select(isin, company_name), copy = TRUE) %&gt;% print(n = 20) # disconnet!!! dbDisconnect(datastore) 27.2 File “simulate_portcheck_code.R” library(readr) library(dplyr) overrides &lt;- read_csv(&quot;https://raw.githubusercontent.com/2DegreesInvesting/PACTA_analysis/master/data/fin_sector_overrides.csv&quot;, col_types = &quot;ccdc&quot;) %&gt;% mutate_at(vars(company_name, corporate_bond_ticker,fin_sector_override), list(as.character)) %&gt;% mutate(sector_override = TRUE) overrides_cbt &lt;- overrides %&gt;% filter(corporate_bond_ticker != &quot;&quot; , !is.na(corporate_bond_ticker)) %&gt;% select(corporate_bond_ticker, fin_sector_override, sector_override) %&gt;% distinct() overrides_bbg &lt;- overrides %&gt;% filter(is.na(corporate_bond_ticker)|corporate_bond_ticker == &quot;&quot;)%&gt;% select(bloomberg_id, fin_sector_override, sector_override) %&gt;% distinct() sector_bridge &lt;- read_csv(&quot;https://raw.githubusercontent.com/2DegreesInvesting/PACTA_analysis/master/data/sector_bridge.csv&quot;, col_types = &quot;ccc&quot;) cb_groups &lt;- c(&quot;Convertible bonds&quot;, &quot;Corporate Bonds&quot;, &quot;Corporate inflation linked Bonds&quot;) sb_groups &lt;- c(&quot;Sovereign Debt&quot;,&quot;Sovereign Agency Debt&quot;, &quot;Government inflation linked Bonds&quot;, &quot;Sovereign&quot;,&quot;Sovereign Agency&quot;, &quot;Sovereigns&quot;) clean_fin_data &lt;- function(input_data) { input_data %&gt;% left_join(sector_bridge %&gt;% filter(source == &quot;BICS&quot;) %&gt;% select(-source), by = c(&quot;security_bics_subgroup&quot; = &quot;industry_classification&quot;), copy = TRUE) %&gt;% filter(!is.na(sector)) %&gt;% select(-security_mapped_sector) %&gt;% rename(security_mapped_sector = sector) %&gt;% left_join(overrides_cbt, by = &quot;corporate_bond_ticker&quot;, copy = TRUE) %&gt;% left_join(overrides_bbg, by = &quot;bloomberg_id&quot;, copy = TRUE) %&gt;% mutate(sector_override = sector_override.x, sector_override = if_else(sector_override.y != &quot;&quot;&amp;!is.na(sector_override.y), sector_override.y, sector_override), fin_sector_override = fin_sector_override.x, fin_sector_override = if_else(!is.na(fin_sector_override.y)&amp;fin_sector_override.y != &quot;&quot;, fin_sector_override.y, fin_sector_override), sector_override = if_else(is.na(sector_override),FALSE,TRUE)) %&gt;% select(-sector_override.x, -sector_override.y, -fin_sector_override.x, -fin_sector_override.y) %&gt;% mutate(security_mapped_sector = if_else(sector_override, fin_sector_override, security_mapped_sector)) %&gt;% select(-fin_sector_override) %&gt;% mutate(asset_type = if_else(asset_type == &quot;Other&quot;, &quot;Others&quot;, asset_type), asset_type = if_else(is.na(asset_type), &quot;Others&quot;, asset_type)) %&gt;% mutate(asset_type = paste0(toupper(substr(asset_type,1,1)),tolower(substr(asset_type,2,nchar(asset_type))))) %&gt;% mutate(security_mapped_sector = case_when(security_mapped_sector == &quot;Others&quot; ~ &quot;Other&quot;, security_mapped_sector == &quot;OIl&amp;Gas&quot; ~ &quot;Oil&amp;Gas&quot;, TRUE ~ security_mapped_sector)) %&gt;% mutate(asset_type = if_else(security_type %in% cb_groups,&quot;Bonds&quot;,asset_type)) %&gt;% mutate(is_sb = case_when(security_type %in% sb_groups ~ TRUE, security_bics_subgroup %in% sb_groups ~ TRUE, TRUE ~ FALSE)) %&gt;% mutate(asset_type = case_when(grepl(&quot;Fund&quot;, security_type) ~ &quot;Funds&quot; , grepl(&quot;ETF&quot;, security_type) ~ &quot;Funds&quot;, grepl(&quot;Fund&quot;, security_bclass4) ~ &quot;Funds&quot; , grepl(&quot;ETF&quot;, security_bclass4) ~ &quot;Funds&quot;, grepl(&quot;Fund&quot;, security_icb_subsector) ~ &quot;Funds&quot; , grepl(&quot;ETF&quot;, security_icb_subsector) ~ &quot;Funds&quot;, TRUE ~ asset_type)) %&gt;% select( company_id, company_name,bloomberg_id,corporate_bond_ticker, country_of_domicile, isin, unit_share_price, exchange_rate_usd, asset_type, security_type, security_mapped_sector, security_icb_subsector, security_bics_subgroup, maturity_date, coupon_value, amount_issued, current_shares_outstanding_all_classes, unit_share_price, sector_override, is_sb ) } "],
["introduction-to-drake.html", "Chapter 28 2020-05-05: Introduction to drake 28.1 Resources", " Chapter 28 2020-05-05: Introduction to drake Much of 2DII’s value stems from our ability to produce quality, reproducible reports. Sometimes, this involves us tweaking portions of the analysis, and manually re-running (hoping that we haven’t broken anything downstream). Drake is a tool that aims to automate and facilitate this process. At this meetup we watched a 6’ video introducing the drake package, and discussed how 2DII might benefit from drake. Jackson (@jdhoffa) lead the meeting and rose lots of interest. Many folks asked questions and Alex (@AlexAxthelm) answered them (Alex co-authors drake). 28.1 Resources Recording The drake R Package User Manual. Benefits of a function-based diet (The {drake} post). "],
["azure-rstudio-server-and-pins.html", "Chapter 29 2020-05-19: Azure, RStudio server, and pins 29.1 Introduction 29.2 Setup an Azure board for pins 29.3 Use an Azure board", " Chapter 29 2020-05-19: Azure, RStudio server, and pins This meetup is structured as a mini-workshop. You learn about three tools you can combine to improve the way you manage data: Azure, RStudio server and the pins package. As a side effect you will also learn a system we plan to use in a longer workshop. Find materials are at https://github.com/2DegreesInvesting/ds-incubator/issues/45; the most important document to follow along is https://bit.ly/dsi-pin-azure. 29.1 Introduction Open 00_intro-rmd.Rmd The goal of this section is to practice the tools we’ll be using later: A collaborative document. Zoom. RMarkdown documents. Managing these three things at once is hard and will likely distract you from learning anything. A little practice will help you will master these tools so you can focus on the content of the lessons to come. 29.1.1 Objective Run a code chunk. Click “yes” on the “Participants” tab on Zoom. Write “hi” in the \"Questions section for this lesson on https://bit.ly/dsi-pin-azure. This is just to ensure you know where we expect you to ask questions. 29.1.2 RMarkdown notebooks This is an R Markdown Notebook. When you execute code within the notebook, the results appear beneath the code. R code goes in code chunks, denoted by three backticks. Try executing this chunk by clicking the Run button within the chunk or by placing your cursor inside it and pressing Crtl+Shift+Enter (Windows) or Cmd+Shift+Enter (Mac). packageVersion(&quot;pins&quot;) 29.2 Setup an Azure board for pins Open 01_setup-azure-board.Rmd 29.2.1 Objective Setup an Azure board for pins. 29.2.2 Setup an Azure board for pins Open your .Renviron file with usethis::edit_r_environ(). Add this: AZURE_STORAGE_CONTAINER=&quot;test-container&quot; AZURE_STORAGE_ACCOUNT=&quot;2diiteststorage&quot; # Not my real key AZURE_STORAGE_KEY=&quot;ABABAB...==&quot; Replace “ABABAB…==” with the value I’ll share privately. Ensure the file ends with a new line. Save, close, and restart R. Set these variables in you .Renviron. See ?usethis::edit_r_environ(). 29.3 Use an Azure board Open 02_use-azure-board.Rmd https://bit.ly/dsi-pin-azure 29.3.1 Objectives Use the pins package and register our Azure board Find datasets in our Azure board Get a dataset from our Azure board Save processed data to the server’s cache Visualize the structure of the server’s cache. 29.3.2 Use the pins package and register our Azure board Use the pins package with library(pins). Register our Azure board with board_register_azure() library(pins) board_register_azure() 29.3.3 Find datasets in our Azure board Find pins on our Azure board from the Connections tab. Find pins on our Azure board with the Addin “Find pins”. Find pins on our Azure board with pin_find(), by name or description. pin_find(&quot;mtc&quot;, board = &quot;azure&quot;) 29.3.4 Get a dataset from our Azure board Get the mtcars dataset from our Azure board with pin_get(). Assign the result to the object mydata. Inspect mydata however you like. How many rows does it have? mydata &lt;- pin_get(&quot;mtcars&quot;, board = &quot;azure&quot;) mydata 29.3.5 Save processed data to the server’s cache Get the head() of mydata and assign it to a new object smalldata. smalldata &lt;- head(mydata) smalldata Store smalldata in you local (server) cache with pin() pin(smalldata) Find “smalldata” in your local (server) cache, however you like. pin_find(&quot;smalldata&quot;) Get “smalldata” from your local (server) cache. pin_get(&quot;smalldata&quot;) 29.3.6 Visualize the structure of the server’s cache. Create a path to the local (server) cache that pins created for you. server_cache &lt;- board_cache_path() server_cache Explore the structure of the local (server) cache with fs::dir_tree(). fs::dir_tree(server_cache) 29.3.7 Takeaways Go to the collaborative document and write your takeaways. &lt;bit.ly/dsi-pin-azure&gt; "],
["wrapping-up-our-discussion-on-how-to-manage-and-use-data.html", "Chapter 30 2020-05-26: Wrapping up our discussion on how to manage and use data", " Chapter 30 2020-05-26: Wrapping up our discussion on how to manage and use data https://github.com/2DegreesInvesting/ds-incubator/issues/46 This meetup wrapped up our discussion about how to improve the way we manage and use data. We covered: The definition of “cache”. Revisit the flow of data. Compare Dropbox versus Azure+pins Discussed commends and questions "],
["last-post-here.html", "Chapter 31 2020-05-27: Last post here", " Chapter 31 2020-05-27: Last post here This is the last post here. The ds-incubator continues but we no longer add chapters to https://2degreesinvesting.github.io/ds-incubator/. Instead, please go to the ds-incubator home page and follow the relevant links. "],
["gotchas-when-moving-code-from-a-script-to-an-r-package.html", "Gotchas when moving code from a script to an R package 31.1 Packaging 31.2 Function interface 31.3 Code smells and feels 31.4 Error prone 31.5 Style", " Gotchas when moving code from a script to an R package 31.1 Packaging 31.1.1 Setup: R, RStudio, Git, GitHub These steps will direct you to relevant chapters from “Happy Git with R” by Jenny Bryan et. al. Register a free GitHub account Install or update R and RStudio Install Git Introduce yourself to Git Prove local Git can talk to GitHub Cache your username and password or set up SSH keys Create and save a GitHub Personal Access Token (PAT) Prove RStudio can find local Git and, therefore, can talk to GitHub 31.1.2 Setup: devtools and testthat Make the devtools and testthat packages available in every R session. Edit your .Rprofile file to include this code (you may use usethis::edit_r_profile()): if (interactive()) { suppressMessages(require(devtools)) suppressMessages(require(testthat)) } (Your .Rprofile should NOT include data analysis packages such as dplyr or ggplot2.) Ensure you always start each session with a blank slate: Save, close and restart R. 31.1.3 use_data_raw(), then use_data() Good. # &gt; Console use_data_raw() # data-raw/dataset-name.R dataset_name &lt;- readxl::read_excel(&quot;data-raw/dataset-name.xlsx&quot;) use_data(dataset_name) # R/dataset_name.R #&#39; A dataset #&#39; &quot;dataset_name&quot; # R/any-file.R f &lt;- function() { dataset_name } Bad. # R/any-file.R dataset_name &lt;- readxl::read_excel(&quot;data/dataset-name.xlsx&quot;) f &lt;- function() { dataset_name } Bad. f &lt;- function() { load(&quot;data/dataset_name.rda&quot;) } http://r-pkgs.had.co.nz/data.html 31.1.4 Consider using internal data Good. # data-raw/my_internal_data.R use_data(my_internal_data, internal = TRUE) # R/any.R f &lt;- function(data) { dplyr::left_join(data, my_internal_data) } Bad. # R/any.R my_internal_data &lt;- mtcars %&gt;% dplyr::select(cyl) f &lt;- function(data) { dplyr::left_join(data, my_internal_data) } http://r-pkgs.had.co.nz/data.html#data-sysdata 31.1.5 use_package(\"dplyr\") not library(dplyr) Good. use_package(&quot;dplyr&quot;) Bad. library(dplyr) https://r-pkgs.org/whole-game.html 31.1.6 namespace::function_from_other_package() Good. f &lt;- function(data) { utils::head(dplyr::select(data, dplyr::last_col())) } Good. #&#39; @importFrom magrittr %&gt;% #&#39; @importFrom utils head #&#39; @importFrom dplyr select last_col f &lt;- function(data) { data %&gt;% select(last_col()) %&gt;% head() } Bad. f &lt;- function(data) { head(select(data, last_col())) } Bad. f &lt;- function(data) { data %&gt;% select(last_col()) %&gt;% head() } 31.1.7 The tidyverse is for EDA, not packages Good. use_package(&quot;dplyr&quot;) use_package(&quot;tidyr&quot;) Bad. use_package(&quot;tidyverse&quot;) https://www.tidyverse.org/blog/2018/06/tidyverse-not-for-packages/ 31.1.8 Use the .data pronoun Good. f &lt;- function(data, column_name) { dplyr::select(data, .data[[column_name]]) } Ok. f &lt;- function(data) { stopifnot(hasName(mtcars, &quot;cyl&quot;)) dplyr::select(data, .data$cyl) } Bad. f &lt;- function(data) { dplyr::select(data, cyl) } https://rlang.r-lib.org/reference/tidyeval-data.html https://dplyr.tidyverse.org/dev/articles/programming.html#how-tos 31.2 Function interface 31.2.1 Avoid relying on the global environment Good. f &lt;- function(data) { data } my_data &lt;- tibble::tibble(x = 1) f(my_data) #&gt; # A tibble: 1 x 1 #&gt; x #&gt; &lt;dbl&gt; #&gt; 1 1 Bad. f &lt;- function(data = my_data2) { data } ls() #&gt; [1] &quot;f&quot; &quot;my_data&quot; try(f()) #&gt; Error in f() : object &#39;my_data2&#39; not found my_data2 &lt;- tibble::tibble(x = 1) ls() #&gt; [1] &quot;f&quot; &quot;my_data&quot; &quot;my_data2&quot; f() #&gt; # A tibble: 1 x 1 #&gt; x #&gt; &lt;dbl&gt; #&gt; 1 1 31.2.2 Avoid modifying the global environment, e.g. with &lt;&lt;- Setup. readr::write_csv(mtcars, &quot;some_data.csv&quot;) Good. some_data_path &lt;- function() { fs::path(&quot;some_data.csv&quot;) } some_data_path() #&gt; some_data.csv read_some_data &lt;- function(path) { suppressMessages(head(readr::read_csv(path))) } path &lt;- some_data_path() # Define path read_some_data(path) #&gt; # A tibble: 6 x 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 Bad. some_data_path &lt;- function() { path &lt;&lt;- &quot;some_data.csv&quot; } read_some_data &lt;- function() { suppressMessages(head(readr::read_csv(path))) } some_data_path() # Define path read_some_data() #&gt; # A tibble: 6 x 11 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 “[Avoid global variables because they] introduce non-obvious dependencies between functions” – Advanced R, Environments). For valid uses of &lt;&lt;- see (Advanced R, Function factories). Clean up. fs::file_delete(&quot;some_data.csv&quot;) 31.2.3 Arguments that provide core data are required Good. f &lt;- function(data) { data } f(mtcars) Bad. f &lt;- function(data = mtcars) { data } f() Arguments that provide core data are required (have no default); they are often called data, x, or y). – Adapted from https://principles.tidyverse.org/args-data-details.html 31.2.4 Descriptor arguments are usually required Good. forecast &lt;- function(data, start_year, time_span = 5) { end_year &lt;- start_year + time_span time_period &lt;- data$year &gt;= start_year &amp; data$year &lt;= end_year data %&gt;% filter(time_period) %&gt;% # ... } Bad. forecast &lt;- function(data, start_year = 2020, time_span = 5) { # ... } Descriptor arguments describe essential details of the operation, and are usually required. – Adapted from https://principles.tidyverse.org/args-data-details.html 31.2.5 Avoid reading and writing operations Unless it is precisely the purpose of your function, avoid operations that read or write data (in general, avoid side effects). Good. f &lt;- function(data) { dplyr::select(data, 1L) } Bad. f &lt;- function(path) { data &lt;- readxl::read_excel(path) dplyr::select(data, 1L) } What is a pure function. Avoid hidden arguments (ds-incubator). 31.3 Code smells and feels 31.3.1 Simplify if() with objects named meaningfully x &lt;- sample(c(1:10), size = 2, replace = TRUE) say &lt;- function(x, msg) paste(paste(x, collapse = &quot;, &quot;), msg) say(1:2, &quot;Hey!&quot;) #&gt; [1] &quot;1, 2 Hey!&quot; Good. is_even_between_5and10 &lt;- (x %% 2 == 0) &amp; dplyr::between(x, 5L, 10L) if (all(is_even_between_5and10)) { say(x, &quot;Yeah!&quot;) } else { say(x, &quot;Nope!&quot;) } #&gt; [1] &quot;8, 9 Nope!&quot; Bad. if (all((x %% 2 == 0) &amp; (x &gt;= 5L) &amp; (x &lt;= 10L))) { say(x, &quot;Yeah!&quot;) } else { say(x, &quot;Nope!&quot;) } #&gt; [1] &quot;8, 9 Nope!&quot; https://speakerdeck.com/jennybc/code-smells-and-feels?slide=36 31.3.2 Program for columns with clean_names Good. f &lt;- function(data) { clean &lt;- r2dii.utils::clean_column_names(data) stopifnot(hasName(clean, &quot;a_column&quot;)) result &lt;- dplyr::select(clean, .data$a_column) r2dii.utils::unclean_column_names(result, data) } f(tibble::tibble(A.Column = 1, Another.Column = 1)) #&gt; # A tibble: 1 x 1 #&gt; A.Column #&gt; &lt;dbl&gt; #&gt; 1 1 Bad. f &lt;- function(data) { dplyr::select(data, .data$A.Column) } f(tibble::tibble(A.Column = 1, Another.Column = 1)) #&gt; # A tibble: 1 x 1 #&gt; A.Column #&gt; &lt;dbl&gt; #&gt; 1 1 ?clean_column_names() 31.3.3 Avoid long-running temporary objects Avoid temporary variables unless they run for only a few, consecutive lines. Good. tmp &lt;- dplyr::filter(mtcars, cyl &gt; 4) tmp &lt;- dplyr::select(tmp, disp) tmp &lt;- head(tmp) # ... more unrelated code Better. mtcars %&gt;% dplyr::filter(cyl &gt; 4) %&gt;% dplyr::select(disp) %&gt;% head() Bad. tmp &lt;- dplyr::filter(mtcars, cyl &gt; 4) tmp &lt;- dplyr::select(tmp, disp) # ... more unrelated code (makes your forget what `tmp` holds) tmp &lt;- head(tmp) 31.3.4 If possible, extract functions to the top level Good. f &lt;- function(x) { g(x) } g &lt;- function(x) { x + 1 } Bad. f &lt;- function(x) { g &lt;- function(x) { x + 1 } g(x) } 31.3.5 Extract commented sections into functions Good. f &lt;- function(x) { y &lt;- calculate_y(x) # ... more code } calculate_y &lt;- function(x) { x^x * x/2L # ... more code specifically about calculating y } Bad. f &lt;- function(x) { # calculate y y &lt;- x^x * x/2L # ... more code specifically about calculating y # ... more code } 31.4 Error prone 31.4.1 Avoid hidden arguments: Extract functions with all arguments Good. f &lt;- function(x, y, z) { x + g(y, z) } g &lt;- function(y, z) { y + z } f(1, 1, 1) #&gt; [1] 3 Bad. # Fragile. f &lt;- function(x, y, z) { g &lt;- function(y) { # `z` is outside of the scope of g(). It&#39;s a hidden argument y + z } x + g(y) } f(1, 1, 1) #&gt; [1] 3 # f() breaks when you move g() to the top level f &lt;- function(x, y, z) { x + g(y) } g &lt;- function(y) { y + z } try(f(1, 1, 1)) #&gt; Error in g(y) : object &#39;z&#39; not found 31.4.2 Separate functions, data, and scripts 31.4.3 A non-package project It’s easy for an analyst to maintain a project when functions, data, and scripts are separate. Good. # R/all-functions.R f &lt;- function(data) { # ... some code } # data/all-datasets.R some_data &lt;- readr::read_csv(here::here(&quot;data-raw&quot;, &quot;some_data.csv&quot;)) # script/this-script.R library(tidyverse) source(here::here(&quot;R&quot;, &quot;all-functions.R&quot;)) source(here::here(&quot;data&quot;, &quot;all-datasets.R&quot;)) f(data = some_data) It is error prone to mix functions, data, and scripts. The mess hides inter dependencies that can break your code unexpectedly. Also, this makes it hard for others to reproduce, or understand your code – the maintainance programmer can only view your code through a toilet paper tube. Bad. # sripts-functions-and-data.R library(tidyverse) some_data &lt;- readr::read_csv(here::here(&quot;data-raw&quot;, &quot;some_data.csv&quot;)) f &lt;- function(some_data) { some_data %&gt;% dplyr::select() %&gt;% # ... more code } f(some_data) 31.4.4 A package project When functions, data, and scripts are separate, it’s easy for a developer to transform a project into an R package. Functions go in the R/ directory, raw data in data-raw/, and data in data/. Scripts become examples, tests, and higher level documentation such as README, and the Home and articles pages of the package-website. 31.4.5 if() uses a single TRUE or FALSE x &lt;- c(1, 2) y &lt;- 0L Good # Good if (identical(x, c(1, 2))) { say(identical(x, c(1, 2)), &quot;is what you gave.&quot;) } #&gt; [1] &quot;TRUE is what you gave.&quot; # Bad if (x == c(1, 2)) { say(x == c(1, 2), &quot;is what you gave.&quot;) } #&gt; Warning in if (x == c(1, 2)) {: the condition has length &gt; 1 and only the first #&gt; element will be used #&gt; [1] &quot;TRUE, TRUE is what you gave.&quot; Caveats: https://github.com/2DegreesInvesting/ds-incubator/issues/13 31.4.6 1 is equal to 1L but not identical Careful! 1 == 1L #&gt; [1] TRUE identical(1, 1L) #&gt; [1] FALSE Good this_integer &lt;- 1L if (!identical(this_integer, 1)) &quot;Not the same&quot; else &quot;Wrong result&quot; #&gt; [1] &quot;Not the same&quot; Bad. this_integer &lt;- 1L if (!this_integer == 1) &quot;Not the same&quot; else &quot;Wrong result&quot; #&gt; [1] &quot;Wrong result&quot; 31.5 Style 31.5.1 Limit your code to 80 characters per line For reference, in RStudio you can set a margin column at 80 characters (Tools &gt; Global Options &gt; Code &gt; Show margin &gt; Margin column). Strive to limit your code to 80 characters per line. This fits comfortably on a printed page with a reasonably sized font. If you find yourself running out of room, this is a good indication that you should encapsulate some of the work in a separate function. – https://style.tidyverse.org/syntax.html#long-lines If a function definition runs over multiple lines, indent the second line to where the definition starts. – https://style.tidyverse.org/functions.html#long-lines-1 31.5.2 Names should use only lowercase letters, numbers, and \"_\". Generally, variable names should be nouns and function names should be verbs. Strive for names that are concise and meaningfully! Reserve dots exclusively for the S3 object system. Good. add_row() permute() Bad. row_adder() permutation() https://style.tidyverse.org/syntax.html#object-names https://style.tidyverse.org/functions.html#naming 31.5.3 Avoid T and F as synonyms for TRUE and FALSE Good sum(1, 1, na.rm = TRUE) Bad. sum(1, 1, na.rm = T) TRUE and FALSE are reserved words; T and F are not. T &lt;- &quot;Whatever&quot; T #&gt; [1] &quot;Whatever&quot; # Forbidden try(TRUE &lt;- &quot;Whatever&quot;) #&gt; Error in TRUE &lt;- &quot;Whatever&quot; : #&gt; invalid (do_set) left-hand side to assignment https://www.r-bloggers.com/r-tip-avoid-using-t-and-f-as-synonyms-for-true-and-false/ 31.5.4 Reserve return() to return early Only use return() for early returns. Otherwise, rely on R to return the result of the last evaluated expression https://style.tidyverse.org/functions.html#return 31.5.5 Return invisibly only when the main purpose is a side effect Good. # Main purpose is a side effect: To throw an error if the input is bad check_f &lt;- function(x) { stopifnot(is.numeric(x)) invisible(x) } Good. # Main purpose is not a side effect. Returning visibly f &lt;- function(x) { x + 1 } f(1) #&gt; [1] 2 Bad. # Main purpose is not a side effect. Returning invisibly f &lt;- function(x) { out &lt;- x + 1 } # Returns invisibly f(1) out &lt;- f(1) out #&gt; [1] 2 "]
]
